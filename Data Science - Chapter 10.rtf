{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang2057{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.19041}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 The Report Structure\par
Before starting the analysis, think about the structure of the report. Will it be a brief report of five or fewer pages, or will it be a longer document running more than 100 pages in length? The structure of the report depends on the length of the document. A brief report is more to the point and presents a summary of key findings. A detailed report incrementally builds the argument and contains details about other relevant works, research methodology, data sources, and intermediate findings along with the main results.\par
\par
I have reviewed reports by leading consultants including Deloitte and McKinsey. I found that the length of the reports varied depending largely on the purpose of the report. Brief reports were drafted as commentaries on current trends and developments that attracted public or media attention. Detailed and comprehensive reports offered a critical review of the subject matter with extensive data analysis and commentary. Often, detailed reports collected new data or interviewed industry experts to answer the research questions.\par
\par
Even if you expect the report to be brief, sporting five or fewer pages, I recommend that the deliverable follow a prescribed format including the cover page, table of contents, executive summary, detailed contents, acknowledgments, references, and appendices (if needed).\par
\par
I often find the cover page to be missing in documents. It is not the inexperience of undergraduate students that is reflected in submissions that usually miss the cover page. In fact, doctoral candidates also require an explicit reminder to include an informative cover page. I hasten to mention that the business world sleuths are hardly any better. Just search the Internet for reports and you will find plenty of reports from reputed firms that are missing the cover page.\par
\par
At a minimum, the cover page should include the title of the report, names of authors, their affiliations, and contacts, the name of the institutional publisher (if any), and the date of publication. I have seen numerous reports missing the date of publication, making it impossible to cite them without the year and month of publication. Also, from a business point of view, authors should make it easier for the reader to reach out to them. Having contact details at the front makes the task easier.\par
\par
"A table of contents (ToC)" is like a map needed for a trip never taken before. You need to have a sense of the journey before embarking on it. A map provides a visual proxy for the actual travel with details about the landmarks that you will pass by in your trip. The ToC with main headings and lists of tables and figures offers a glimpse of what lies ahead in the document. Never shy away from including a ToC, especially if your document, excluding cover page, table of contents, and references, is five or more pages in length.\par
\par
Even for a short document, I recommend an "abstract" or an "executive summary". Nothing is more powerful than explaining the crux of your arguments in three paragraphs or less. Of course, for larger documents running a few hundred pages, the executive summary could be longer. An "introductory section" is always helpful in setting up the problem for the reader who might be new to the topic and who might need to be gently introduced to the subject matter before being immersed in intricate details. A good follow-up to the introductory section is a review of available relevant research on the subject matter. The length of the literature review section depends upon how contested the subject matter is. In instances where the vast majority of researchers have concluded in one direction, the literature review could be brief with citations for only the most influential authors on the subject. On the other hand, if the arguments are more nuanced with caveats aplenty, then you must cite the relevant research to offer adequate context before you embark on your analysis. You might use the literature review to highlight gaps in the existing knowledge, which your analysis will try to fill. This is where you formally introduce your research questions and hypothesis.\par
\par
In the "methodology" section, you introduce the research methods and data sources you used for the analysis. If you have collected new data, explain the data collection exercise in some detail. You will refer to the literature review to bolster your choice for variables, data, and methods and how they will help you answer your research questions.\par
\par
The results section is where you present your empirical findings. Starting with descriptive statistics (see Chapter 4, "Serving Tables") and illustrative graphics (see Chapter S, "Graphic Details" for plots and Chapter 10, "Spatial Data Analytics" for maps), you will move toward formally testing your hypothesis (see Chapter 6, "Hypothetically Speaking").\par
\par
In case you need to run statistical models, you might turn to regression models (see Chapter 7, "Why Tall Parents Don't Have Even Taller Children") or categorical analysis (see Chapters 8, "To Be or Not to Be" and 2., "Categorically Speaking About Categorical Data"). If you are working with time-series data, you can turn to Chapter 11, Doing Serious Time with Time Series. You can also report results from other empirical techniques that fall under the general rubric of data mining (see Chapter 12, "Data Mining for Gold"). Note that many reports in the business sector present results in a more palatable fashion by holding back the statistical details and relying on illustrative graphics to summarize the results.\par
\par
The results section is followed by the discussion section, where you craft your main arguments by building on the results you have presented earlier.\par
\par
The "discussion section" is where you rely on the power of narrative to enable numbers to communicate your thesis to your readers. You refer the reader to the research question and the knowledge gaps you identified earlier. You highlight how your findings provide the ultimate missing piece to the puzzle.\par
\par
Of course, not all analytics return a smoking gun. At times, more frequently than I would like to acknowledge, the results provide only a partial answer to the question and that, too, with a long list of caveats.\par
\par
In the "conclusion" section, you generalize your specific findings and take on a rather marketing approach to promote your findings so that the reader does not remain stuck in the caveats that you have voluntarily outlined earlier. You might also identify future possible developments in research and applications that could result from your research. What remains is housekeeping, including a list of references, the acknowledgment section (acknowledging the support of those who have enabled your work is always good), and "appendices", if needed.\par
\par
Have You Done Your Job as a Writer?\par
As a data scientist, you are expected to do thorough analysis with the appropriate data, deploying the appropriate tools. As a writer, you are responsible for communicating your findings to the readers. Transport Policy, a leading research publication in transportation planning, offers a checklist for authors interested in publishing with the journal. The checklist is a series of questions authors are expected to consider before submitting their manuscripts to the journal. I believe the checklist is useful for budding data scientists and, therefore, I have reproduced it verbatim for their benefit.\par
\par
Have you told readers, at the outset, what they might gain by reading your paper?\par
\par
Have you made the aim of your work clear?\par
\par
Have you explained the significance of your contribution?\par
\par
Have you set your work in the appropriate context by giving sufficient background (including a complete set of relevant references) to your work?\par
\par
Have you addressed the question of practicality and usefulness?\par
\par
Have you identified future developments that might result from your work?\par
\par
Have you structured your paper in a clear and logical fashion?\par
\par
\par
The final task of this capstone project is to create a presentation based on the outcomes of all tasks in previous modules and labs. Your presentation will develop into a story of all your data science journey in this project, and it should be compelling and easy to understand.\par
\par
In the next exercise, you can find a provided PowerPoint template to help you get started to create a report in slides format. However, you are free to add additional slides, charts, and tables.\par
\par
Note that this presentation will be prepared for your peer-data-scientists whom are eager to understand every technical detail of this project. As such, this presentation will be much more detailed and technical than regular high-level and abstracted presentation for your executive team.\par
\par
Once you have completed a detailed report, it should be straightforward for you to abstract it into a high-level deck for your executive team and/or stakeholders.\par
\par
There are a total of 40 points possible for the final assessment, and you will be graded by your peers, who are also completing this assignment.\par
\par
The main grading criteria will be:\par
\par
Uploaded the URL of your GitHub repository including all the completed notebooks and Python files (1 pt)\par
Uploaded your completed presentation in PDF format (1 pt)\par
Completed the required Executive Summary slide (1 pt)\par
Completed the required Introduction slide (1 pt)\par
Completed the required data collection and data wrangling methodology related slides (1 pt)\par
Completed the required EDA and interactive visual analytics methodology related slides (3 pts)\par
Completed the required predictive analysis methodology related slides (1 pt)\par
Completed the required EDA with visualization results slides (6 pts)\par
Completed the required EDA with SQL results slides (10 pts)\par
Completed the required interactive map with Folium results slides (3 pts)\par
Completed the required Plotly Dash dashboard results slides (3 pts)\par
Completed the required predictive analysis (classification) results slides (6 pts)\par
Completed the required Conclusion slide (1 pts)\par
Applied your creativity to improve the presentation beyond the template (1 pts)\par
Displayed any innovative insights (1 pts)\par
You will not be judged on:\par
\par
Your English language, including spelling or grammatical mistakes\par
The content of any text or image(s) or where a link is hyperlinked to\par
\par
\par
\par
Summary of the Data Science Cource by IBM\par
\par
Let us start with Chapter 1 which treats the general question what exactly data science is.\par
\par
As seen in Week 1, Data science is the field in which any given question is answered using data, and/or give recommendations. This data is usually explored, maniplulated and finally analyzed using certain techniques.\par
\par
Big Data, 5 V's: Velocity, Volume, Variaty, Veracity, Value.\par
But when is some dataset called a big data set. usually then it is large enough, has enough velocity and volume and if it can not be handled traditionally.\par
\par
Data mining pipeline\par
 - Establish goals/Costs or ask the right questions\par
 - selecting data to ensure quality of the data\par
 - preprocessing data for the integrity, i.e. is there any data missing!\par
 - transform and storage data, e.g. format or reduce it\par
 - data mining using descriptive methods or using machine learning tecniques\par
 - evaluation in/out-sample forecast.\par
\par
(Open Source) tools for Data scientist\par
\par
Since commerercial tools are rather reserved for businesses, we omit them and solely concentrate on open source tools. Before we give any tools, it must be clear for what these tools are being used. Therefore we give a rough procecure what there is to do:\par
First we start with Data management which becomes useful for larger datasets. These are usually stored in databases, mostly in relational databases somewhat based on SQL. Thereby, one can make use of MySQL or PostgreSQL, or in the NoSQL case one can use mongoDB or coachDB. But, there is also the more unusual way of handling data with lots of files. They can be organized using Hadoop or coph.\par
Once the data is properly managed, we need to extract, load and transform (ELT) it. This phase is called data Integration. Besides techniques in Python which we usually use, one can make use of Apache Airflow or Kaffe or nifi, or use Spark SQL. It must be said, that this part takes a huge amount of time in the general data science methology! Let us move on to Data visualization. This can be done using Hue, kibana or Apache superset.\par
Regarding the acutual analysis, this is done in the Model deployment phase where predictionIO or Seldon might be tools to use. Afterwards,the models are monitored or assed  using ModelDB or Prometheus.\par
At last, one has to make a remark about Code Asset mangement. But this is a simple one since GitHub using git is the most common solution. \par
\par
As mentioned above, we will mostly work with the language Python as a part of Jupyter Notebooks. As they are server based, Skill Network Labs will provide us an interactive environment to write them. Besides Python, Jupyter Notebooks are also capable of understanding the more statistical orientated language R and Scala, which has its origin in scientific computing. Anyway, they are interactive meaning that they can be executed in chunks in contrary to the all-or-none approach.\par
\par
\par
\par
}
 